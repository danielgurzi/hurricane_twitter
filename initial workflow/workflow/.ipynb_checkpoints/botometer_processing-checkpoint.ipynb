{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Botometer Processing Notebook\n",
    "\n",
    "We decided to use a Python package called to Botometer to help with our analysis. The Botometer is a tool developed by researchers at the Indiana University Network Science Institute (IUNI) and the Center for Complex Networks and Systems Research (CNetS). Scores are displayed as percentages. These percentages are the probability that a twitter account is human or bot; the closer to 0 a score is the higher the likelihood it is a human and the closer to 1 a score is the higher the likelihood it is a bot. According to the Botometer’s website, the “probability calculation uses Bayes’ theorem to take into account an estimate of the overall prevalence of bots, so as to balance false positives with false negatives”.(https://botometer.iuni.iu.edu/#!/faq#what-is-cap) For more information, See Maninder's blog post about the Botometer here: https://medium.com/@m.virk1/botometer-eac76a270516. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents:\n",
    "- [Reading in and Inspecting Data](#Reading-in-and-Inspecting-Data)\n",
    "- [Getting the Botometer Running](#Getting-the-Botometer-Running)\n",
    "- [Making a Usable DataFrame from Botometer Data](#Making-a-Usable-DataFrame-from-Botometer-Data)\n",
    "- [Merging, Inspecting, and Preparing the DataFrame](#Merging,-Inspecting,-and-Preparing-the-DataFrame)\n",
    "- [Prepping Data for NLP Classification Modeling ](#Prepping-Data-for-NLP-Classification-Modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "py38\n"
     ]
    }
   ],
   "source": [
    "!echo $CONDA_DEFAULT_ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Importing packages needed for Data Cleaning and EDA\n",
    "import os\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import botometer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in and Inspecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Reading in my proprocessed csv to pandas\n",
    "twitter = pd.read_csv('./data/hurricaneharvey/twitter_retrieval/hurricaneharvey_10000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 15)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape of my dataframe \n",
    "twitter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>to</th>\n",
       "      <th>text</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>replies</th>\n",
       "      <th>id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>author_id</th>\n",
       "      <th>date</th>\n",
       "      <th>formatted_date</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>geo</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChrisTheYank</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Handing out more along with church folk suppli...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>914260113971646464</td>\n",
       "      <td>https://twitter.com/ChrisTheYank/status/914260...</td>\n",
       "      <td>342548477</td>\n",
       "      <td>2017-09-30 22:46:11+00:00</td>\n",
       "      <td>Sat Sep 30 22:46:11 +0000 2017</td>\n",
       "      <td>#HurricanHarvey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.instagram.com/p/BZrrOONjmQj/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>projectcostello</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Houston Brewery supports #HurricanHarvey relie...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>914152662379180033</td>\n",
       "      <td>https://twitter.com/projectcostello/status/914...</td>\n",
       "      <td>1915260643</td>\n",
       "      <td>2017-09-30 15:39:13+00:00</td>\n",
       "      <td>Sat Sep 30 15:39:13 +0000 2017</td>\n",
       "      <td>#HurricanHarvey #HoustonStrong</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>myfriend_bella</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our #cat friends effected by #HurricanHarvey n...</td>\n",
       "      <td>18</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>913975189163167745</td>\n",
       "      <td>https://twitter.com/myfriend_bella/status/9139...</td>\n",
       "      <td>3341234925</td>\n",
       "      <td>2017-09-30 03:54:00+00:00</td>\n",
       "      <td>Sat Sep 30 03:54:00 +0000 2017</td>\n",
       "      <td>#cat #HurricanHarvey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.gofundme.com/bellasbigadventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jaygirl1980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#MTPDaily - Trump gets a lot of credit for #Hu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>913883732070846465</td>\n",
       "      <td>https://twitter.com/jaygirl1980/status/9138837...</td>\n",
       "      <td>34695570</td>\n",
       "      <td>2017-09-29 21:50:35+00:00</td>\n",
       "      <td>Fri Sep 29 21:50:35 +0000 2017</td>\n",
       "      <td>#MTPDaily #HurricanHarvey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSHHann</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Day 34 of #hurricanharvey response w/ @RedCros...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>913832053791182848</td>\n",
       "      <td>https://twitter.com/LSHHann/status/91383205379...</td>\n",
       "      <td>1586818135</td>\n",
       "      <td>2017-09-29 18:25:14+00:00</td>\n",
       "      <td>Fri Sep 29 18:25:14 +0000 2017</td>\n",
       "      <td>#hurricanharvey</td>\n",
       "      <td>@RedCross</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username   to                                               text  \\\n",
       "0     ChrisTheYank  NaN  Handing out more along with church folk suppli...   \n",
       "1  projectcostello  NaN  Houston Brewery supports #HurricanHarvey relie...   \n",
       "2   myfriend_bella  NaN  Our #cat friends effected by #HurricanHarvey n...   \n",
       "3      jaygirl1980  NaN  #MTPDaily - Trump gets a lot of credit for #Hu...   \n",
       "4          LSHHann  NaN  Day 34 of #hurricanharvey response w/ @RedCros...   \n",
       "\n",
       "   retweets  favorites  replies                  id  \\\n",
       "0         0          0        0  914260113971646464   \n",
       "1         1          2        0  914152662379180033   \n",
       "2        18         44        0  913975189163167745   \n",
       "3         1          1        2  913883732070846465   \n",
       "4         0          1        0  913832053791182848   \n",
       "\n",
       "                                           permalink   author_id  \\\n",
       "0  https://twitter.com/ChrisTheYank/status/914260...   342548477   \n",
       "1  https://twitter.com/projectcostello/status/914...  1915260643   \n",
       "2  https://twitter.com/myfriend_bella/status/9139...  3341234925   \n",
       "3  https://twitter.com/jaygirl1980/status/9138837...    34695570   \n",
       "4  https://twitter.com/LSHHann/status/91383205379...  1586818135   \n",
       "\n",
       "                        date                  formatted_date  \\\n",
       "0  2017-09-30 22:46:11+00:00  Sat Sep 30 22:46:11 +0000 2017   \n",
       "1  2017-09-30 15:39:13+00:00  Sat Sep 30 15:39:13 +0000 2017   \n",
       "2  2017-09-30 03:54:00+00:00  Sat Sep 30 03:54:00 +0000 2017   \n",
       "3  2017-09-29 21:50:35+00:00  Fri Sep 29 21:50:35 +0000 2017   \n",
       "4  2017-09-29 18:25:14+00:00  Fri Sep 29 18:25:14 +0000 2017   \n",
       "\n",
       "                         hashtags   mentions  geo  \\\n",
       "0                 #HurricanHarvey        NaN  NaN   \n",
       "1  #HurricanHarvey #HoustonStrong        NaN  NaN   \n",
       "2            #cat #HurricanHarvey        NaN  NaN   \n",
       "3       #MTPDaily #HurricanHarvey        NaN  NaN   \n",
       "4                 #hurricanharvey  @RedCross  NaN   \n",
       "\n",
       "                                          urls  \n",
       "0     https://www.instagram.com/p/BZrrOONjmQj/  \n",
       "1                                          NaN  \n",
       "2  https://www.gofundme.com/bellasbigadventure  \n",
       "3                                          NaN  \n",
       "4                                          NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing what my dataframe looks like \n",
    "twitter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8574"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing how many unique user names there are in my dataframe \n",
    "twitter['username'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Botometer Running "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Putting my usernames in a list for processing in the botometer \n",
    "username_list = twitter['username'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Where one would put in their Twitter API credentials and rapid api key and then instantiate a botometer \n",
    "rapidapi_key = \"4ef98cfe9dmsh457741e02725da2p11bfe4jsnac866de8c63b\" # now it's called rapidapi key\n",
    "twitter_app_auth = {\n",
    "    'consumer_key' : \"Rl7XLgYVy7LYx8A0z848Iu8t3\",#os.environ['TWITTER_CONSUMER_KEY'] \n",
    "        'consumer_secret' : \"SVsuERsHKCC2SzXW1krC7es7RuICItaQc6cJD10AL1DBjrvKyP\",#os.environ['TWITTER_CONSUMER_SECRET'] \n",
    "        'access_token' : \"16955613-1Px1BShX49NFwfk9VpGSJTUHIp8ORrwn3Bc1IOEeY\",#os.environ['TWITTER_ACCESS_TOKEN'] \n",
    "        'access_secret' : \"W69uaFID4GaEEUmNyW0jhB6yOHuWXi8fZTh1gcKbpNiHz\",#os.environ['TWITTER_ACCESS_SECRET']  # \n",
    "  }\n",
    "bom = botometer.Botometer(wait_on_ratelimit=True,\n",
    "                          rapidapi_key=rapidapi_key,\n",
    "                          **twitter_app_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Check a sequence of accounts\n",
    "results = []    \n",
    "accounts = username_list\n",
    "for screen_name, result in bom.check_accounts_in(accounts):\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the length of my results to make sure I got what I was expecting \n",
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a Usable DataFrame from Botometer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cap'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-5e53d988d069>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Going through a series of pandas code to make my dataframe into just the username and botrating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0musers_and_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0musers_and_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cap'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0musers_and_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cap'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0musers_and_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bot_rating'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0musers_and_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cap'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0musers_and_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0musers_and_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cap'"
     ]
    }
   ],
   "source": [
    "# Taking my result list and making it into a dataframe called users_and_scores\n",
    "# Going through a series of pandas code to make my dataframe into just the username and botrating \n",
    "users_and_scores = pd.DataFrame(results)\n",
    "users_and_scores['cap'] = users_and_scores['cap'].astype(str)\n",
    "users_and_scores['bot_rating'] = users_and_scores['cap'].str.slice(12,30)\n",
    "users_and_scores['user'] = users_and_scores['user'].astype(str)\n",
    "users_and_scores['user'] = [data.split('screen_name')[-1] for data in users_and_scores['user']]\n",
    "users_and_scores['user'] = users_and_scores['user'].str.replace(\"'\", \"\")\n",
    "users_and_scores['user'] = users_and_scores['user'].replace(\" \", \"\")\n",
    "users_and_scores['user'] = users_and_scores['user'].str.replace(\":\", \"\")\n",
    "users_and_scores['user'] = users_and_scores['user'].str.replace(\"'\", \"\")\n",
    "users_and_scores['username'] = users_and_scores['user'].str.replace(\"}\", \"\")\n",
    "users_and_scores = users_and_scores.drop(columns=['cap', 'categories', 'display_scores', 'scores', 'user', 'error'])\n",
    "users_and_scores['bot_rating'] = pd.to_numeric(users_and_scores['bot_rating'], errors='coerce')\n",
    "users_and_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"TweepError: [{'code': 32, 'message': 'Could not authenticate you.'}]\"]\n"
     ]
    }
   ],
   "source": [
    "print(users_and_scores.iloc[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Checking the shape of my dataframe \n",
    "users_and_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# making a file called twitter 2 with the same indexing as I used on my username list\n",
    "# Reseting the index and eliminating the hashtag in the username\n",
    "# Saving my work to a csv just in case, also moving the number up by one\n",
    "twitter2 = twitter\n",
    "twitter2 = twitter2.reset_index()\n",
    "twitter2['username'] = twitter2['username'].str.replace('@', '')\n",
    "twitter2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging, Inspecting, and Preparing the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Merging my dataframe on the index, also doing .head to make sure the usernames match on both sides \n",
    "twitter_bots = twitter2.merge(users_and_scores, left_index=True, right_index=True)\n",
    "twitter_bots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Doing tail to make sure the usernames match on both sides\n",
    "twitter_bots.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Checking the shape \n",
    "twitter_bots.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns and renaming others, dropping null values, and saving my work to a csv\n",
    "twitter_bots= twitter_bots.drop(columns=['username_y', 'id', 'link', 'index'])\n",
    "twitter_bots = twitter_bots.rename(columns={\"username_x\": \"username\"})\n",
    "twitter_bots.dropna(inplace=True)\n",
    "twitter_bots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Checking the shape after nulls dropped\n",
    "twitter_bots.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Looking at the info \n",
    "twitter_bots.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepping Data for NLP Classification Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Making one column for text variables, dropping columns, and replacing underscore with a space \n",
    "# Saving my work\n",
    "twitter_bots['words'] = twitter_bots['username'] + ' ' + twitter_bots['hashtags'] + ' ' + twitter_bots['text'] + ' ' + twitter_bots['mentions'] + ' ' + twitter_bots['tweet_to']\n",
    "twitter_bots.drop(columns=['username', 'text', 'hashtags', 'mentions', 'tweet_to'], inplace=True)\n",
    "twitter_bots['words'] = twitter_bots['words'].str.replace('_', ' ')\n",
    "twitter_bots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Dropping duplicates \n",
    "twitter_bots = twitter_bots.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Checking out the nulls and object types \n",
    "twitter_bots.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Checking the shape of my dataframe \n",
    "twitter_bots.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Dropping null values\n",
    "twitter_bots.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Making sure all the bot_ratings are numeric, since I made them strings to manipulate the dataframe \n",
    "twitter_bots['bot_rating'] = pd.to_numeric(twitter_bots['bot_rating'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "twitter_bots.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Seeing how my data looks one last time before saving it to a csv\n",
    "twitter_bots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Checking the shape one last time \n",
    "twitter_bots.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Saving my mega dataframe to a csv\n",
    "twitter_bots.to_csv('./data/twitter_preprocessed_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
